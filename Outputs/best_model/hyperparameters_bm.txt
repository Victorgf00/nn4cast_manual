{'num_layers': 4, 'units_0': 256, 'units_1': 64, 'activations_0': 'linear', 'kernel_regularizer': 'l2', 'batch_normalization': 'True', 'he_initialization': 'False', 'learning_rate': 0.0001, 'dropout': 0.1, 'units_2': 16, 'units_3': 64, 'activations_1': 'linear', 'activations_2': 'linear'}